# -*- coding: utf-8 -*-
"""1_tweet_collect_en.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m43YazGlHnL43XAssWaL5QwMoXEFIAbd

# Emoji Sentiment Analysis with Tweets
        
## step1-Data collection
1. querry for data from twitter api
    - period: 2022-0415-2022-0528
    - filter: retweet or media
    - querry:tweeets that contain at least one concerned emoji

![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTigQWzoYCNiDyrz1BN4WTf2X2k9OZ_yvW-FsmcIMsdS9fppNmh)

In this section, we refer to [Ian D. Wood, Sebastian Ruder, 2016](https://www.researchgate.net/publication/321057905_Emoji_as_Emotion_Tags_for_Tweets) to choose commonly used emojis.
"""

# # Authentication info
# import tweepy
# consumer_key = 'B1HITEZpHcS4isYU492RaBKcu'
# consumer_secret = 'qiO3lHo2VECACt50My2Y6eozkliAiEMkbD967MA9BFmDhD3Z4l'
# access_token = '1355036933823541248-PAxS6qX9CqpmB2wVHDcmIcmmM9fnZa'
# access_token_secret = 'vcH5ikw31xpyaqPzCCBy5Rf0y2Et6gdZsLFhM5SVUUbe4'

# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
# auth.set_access_token(access_token, access_token_secret)
# api = tweepy.API(auth, proxy='http://127.0.0.1:7890')

"""## Scraping English Tweets with emojis

### step 1.1: construct a list of common emojis
![image-2.png](attachment:image-2.png)

### step 1.2: def querry

### step 1.3: scraping and save to csv

-------
## 1.1, list of common emojis
In this section, we refer to [Ian D. Wood, Sebastian Ruder, 2016](https://www.researchgate.net/publication/321057905_Emoji_as_Emotion_Tags_for_Tweets) to choose commonly used emojis.
"""

joy = ['\U0001F600', '\U0001F602', '\U0001F603', '\U0001F604',
          '\U0001F606', '\U0001F607', '\U0001F609', '\U0001F60A',
          '\U0001F60B', '\U0001F60C', '\U0001F60D', '\U0001F60E',
          '\U0001F60F', '\U0001F31E', '\U0000263A', '\U0001F618',
          '\U0001F61C', '\U0001F61D', '\U0001F61B', '\U0001F63A',
          '\U0001F638', '\U0001F639', '\U0001F63B', '\U0001F63C',
          '\U00002764', '\U0001F496', '\U0001F495', '\U0001F601',
          '\U00002665']#joy

anger = ['\U0001F62C', '\U0001F620', '\U0001F610',
          '\U0001F611', '\U0001F620', '\U0001F621', '\U0001F616',
          '\U0001F624', '\U0001F63E']#anger
disgust= ['\U0001F4A9']#disgust
fear = ['\U0001F605', '\U0001F626', '\U0001F627', '\U0001F631',
          '\U0001F628', '\U0001F630', '\U0001F640']#fear
sad = ['\U0001F614', '\U0001F615', '\U00002639', '\U0001F62B',
          '\U0001F629', '\U0001F622', '\U0001F625', '\U0001F62A',
          '\U0001F613', '\U0001F62D', '\U0001F63F', '\U0001F494']#sad
surp = ['\U0001F633', '\U0001F62F', '\U0001F635', '\U0001F632']#surprise

emojis = joy + anger + disgust + fear + sad + surp
print(emojis)
print(len(emojis))

"""## 1.2. define querry"""

# decide the scrabing
# there is a limitation in twitter api per month
# we are about to firstly craw approximately 100,000 Tweets.
# To balance the sample, we calculate the required scale of each group separately
# The weight is the number of emojis containted in each group
sum = 10000000
list = [joy, anger, disgust, fear, sad, surp]
maxquerry = []
for group in list:
    sample = int((sum/62)*len(group))
    maxquerry.append(sample)
print(maxquerry)

# Twitter API Authentication
import tweepy
consumer_key = 'B1HITEZpHcS4isYU492RaBKcu'
consumer_secret = 'qiO3lHo2VECACt50My2Y6eozkliAiEMkbD967MA9BFmDhD3Z4l'
access_token = '1355036933823541248-PAxS6qX9CqpmB2wVHDcmIcmmM9fnZa'
access_token_secret = 'vcH5ikw31xpyaqPzCCBy5Rf0y2Et6gdZsLFhM5SVUUbe4'

auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth,wait_on_rate_limit=True)#proxy and automatically set timeout

proxy='http://127.0.0.1:7890'

date = '2024-01-10'

"""## 1.3. crawing data"""

# check the existing data

import pandas as pd
df = pd.read_csv('tweets3.csv')

# # for data cleaning purpose
# # drop the repeated headers
# df = df[df['id'] != 'id']
# df = df.drop_duplicates()

# # define the 'id'
# # the larger the id is, the more recent the tweet is
# # by defining the last id, we could avoid repeating crawing
# lastid = df['id'].max()

"""### 1.1 joy-related tweets"""

# define the search request keywords
# since the URL-encoded search query of 500 characters maximum, we seperately send the requests

# 1-joy related emojis:
keywords = ' OR '.join(joy)
keywords

max_tweets = maxquerry[0]
count = int(max_tweets/7)
print('For this stream of emoji, we collect {} Tweets'.format(max_tweets))
print('For each day in the past week, we collect {} Tweets'.format(count))
lastid = df['id'].max()
lastid

import tweepy
import csv
t = 'joy'


print ('Twritter api:', api)
# at least contains one relevant emoji
#filting retweets and tweets with media
query = keywords +'-filter:retweets'+'-filter:media'
print ('Search for Tweets containing at least one of the following emoji', query)

csvFile = open('tweets3.csv', 'a')
csvWriter = csv.writer(csvFile)
header = ['id','time', 'tweets','source','entities','retweet','favorite','type']

if lastid == '':
    csvWriter.writerow(header) #write header to csv
    try:
        search = tweepy.Cursor(api.search_tweets,
                          q=query,
                          count=count,
                          result_type='recent',
                          lang='en',
                          until=date).items()
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

else:
    try:
        search = tweepy.Cursor(api.search_tweets,
                               q=query,
                              count=count,
                              result_type='recent',
                              lang='en',
                               until=date,
                              max_id=lastid).items()
        # the bigger the id is, the older the Tweet is.
        # max_id setting means the scraped Tweets is older than the the oldest one we have so far
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

csvFile.close()

# check the exsiting data
df = df[df['id'] != 'id']
df = df.drop_duplicates()
df.query('type == "joy"')

"""### 1.2 fear-related tweets"""

###
# 2-fear
keywords = ' OR '.join(fear)
keywords

max_tweets = maxquerry[3]
count = int(max_tweets/7)
print('For this stream of emoji, we collect {} Tweets'.format(max_tweets))
print('For each day in the past week, we collect {} Tweets'.format(count))
lastid

import tweepy
import csv
import time
t = 'fear'
lastid = df['id'].max()

print ('Twritter api:', api)
# at least contains one relevant emoji
#filting retweets and tweets with media
query = keywords +'-filter:retweets'+'-filter:media'
print ('Search for Tweets containing at least one of the following emoji', query)

csvFile = open('tweets3.csv', 'a')
csvWriter = csv.writer(csvFile)
header = ['id','time', 'tweets','source','entities','retweet','favorite','type']

if lastid == '':
#     csvWriter.writerow(header) #write header to csv
    try:
        search = tweepy.Cursor(api.search_tweets,
                          q=query,
                          count=count,
                          result_type='recent',
                          lang='en',
                          until=date).items()
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except tweepy.error.TweepError:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

else:
    try:
        search = tweepy.Cursor(api.search_tweets,
                               q=query,
                              count=count,
                              result_type='recent',
                              lang='en',
                               until=date,
                              max_id=lastid).items()
        # the bigger the id is, the older the Tweet is.
        # max_id setting means the scraped Tweets is older than the the oldest one we have so far
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

csvFile.close()

df = pd.read_csv('tweets3.csv',converters={'id':str})
df = df[df['id'] != 'id']
df = df.drop_duplicates()
lastid = df['id'].max()
df.query('type == "fear"')

###
# 3-sad
keywords = ' OR '.join(sad)
lastid = df['id'].max()
keywords
lastid

max_tweets = maxquerry[4]
count = int(max_tweets/7)
print('For this stream of emoji, we collect {} Tweets'.format(max_tweets))
print('For each day in the past week, we collect {} Tweets'.format(count))
lastid

import tweepy
import csv
t = 'sad'

print ('Twritter api:', api)
# at least contains one relevant emoji
#filting retweets and tweets with media
query = keywords +'-filter:retweets'+'-filter:media'
print ('Search for Tweets containing at least one of the following emoji', query)

csvFile = open('tweets3.csv', 'a')
csvWriter = csv.writer(csvFile)
header = ['id','time', 'tweets','source','entities','retweet','favorite','type']

if lastid == '':
    csvWriter.writerow(header) #write header to csv
    try:
        search = tweepy.Cursor(api.search_tweets,
                          q=query,
                          count=count,
                          result_type='recent',
                          lang='en',
                          until=date).items()
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

else:
    try:
        search = tweepy.Cursor(api.search_tweets,
                               q=query,
                              count=count,
                              result_type='recent',
                              lang='en',
                               until=date,
                              max_id=lastid).items()
        # the bigger the id is, the older the Tweet is.
        # max_id setting means the scraped Tweets is older than the the oldest one we have so far
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

csvFile.close()

df = pd.read_csv('tweets3.csv',converters={'id':str})
df = df[df['id'] != 'id']
df = df.drop_duplicates()
lastid = df['id'].max()

df.query('type == "sad"')

#############

###
# 4-anger
keywords = ' OR '.join(anger)
keywords

max_tweets = maxquerry[1]
count = int(max_tweets/7)
print('For this stream of emoji, we collect {} Tweets'.format(max_tweets))
print('For each day in the past week, we collect {} Tweets'.format(count))
lastid = df['id'].max()

import tweepy
import csv
t = 'anger'
lastid = df['id'].max()

print ('Twritter api:', api)
# at least contains one relevant emoji
#filting retweets and tweets with media
query = keywords +'-filter:retweets'+'-filter:media'
print ('Search for Tweets containing at least one of the following emoji', query)

csvFile = open('tweets3.csv', 'a')
csvWriter = csv.writer(csvFile)
header = ['id','time', 'tweets','source','entities','retweet','favorite','type']

if lastid == '':
#     csvWriter.writerow(header) #write header to csv
    try:
        search = tweepy.Cursor(api.search_tweets,
                          q=query,
                          count=count,
                          result_type='recent',
                          lang='en',
                          until=date).items()
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

else:
    try:
        search = tweepy.Cursor(api.search_tweets,
                               q=query,
                              count=count,
                              result_type='recent',
                              lang='en',
                               until=date,
                              max_id=lastid).items()
        # the bigger the id is, the older the Tweet is.
        # max_id setting means the scraped Tweets is older than the the oldest one we have so far
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

csvFile.close()

df = pd.read_csv('tweets3.csv',converters={'id':str})
df = df[df['id'] != 'id']
df = df.drop_duplicates()
lastid = df['id'].max()

df.query('type == "anger"')

#############

###
# 5-surprise
keywords = ' OR '.join(surp)
keywords

max_tweets = maxquerry[5]
count = int(max_tweets/7)
print('For this stream of emoji, we collect {} Tweets'.format(max_tweets))
print('For each day in the past week, we collect {} Tweets'.format(count))
lastid = df['id'].max()

import tweepy
import csv
t = 'surprise'
lastid = df['id'].max()

print ('Twritter api:', api)
# at least contains one relevant emoji
#filting retweets and tweets with media
query = keywords +'-filter:retweets'+'-filter:media'
print ('Search for Tweets containing at least one of the following emoji', query)

csvFile = open('tweets3.csv', 'a')
csvWriter = csv.writer(csvFile)
header = ['id','time', 'tweets','source','entities','retweet','favorite','type']

if lastid == '':
    csvWriter.writerow(header) #write header to csv
    try:
        search = tweepy.Cursor(api.search_tweets,
                          q=query,
                          count=count,
                          result_type='recent',
                          lang='en',
                          until=date).items()
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

else:
    try:
        search = tweepy.Cursor(api.search_tweets,
                               q=query,
                              count=count,
                              result_type='recent',
                              lang='en',
                               until=date,
                              max_id=lastid).items()
        # the bigger the id is, the older the Tweet is.
        # max_id setting means the scraped Tweets is older than the the oldest one we have so far
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

csvFile.close()

df = pd.read_csv('tweets3.csv',converters={'id':str})
df = df[df['id'] != 'id']
df = df.drop_duplicates()

lastid = df['id'].max()
df.query('type == "surprise"')

#############

###
# 5-disgust
keywords = ' OR '.join(disgust)
keywords

max_tweets = maxquerry[2]
count = int(max_tweets/7)
print('For this stream of emoji, we collect {} Tweets'.format(max_tweets))
print('For each day in the past week, we collect {} Tweets'.format(count))
lastid

import tweepy
import csv
t = 'disgust'
lastid = df['id'].max()

print ('Twritter api:', api)
# at least contains one relevant emoji
#filting retweets and tweets with media
query = keywords +'-filter:retweets'+'-filter:media'
print ('Search for Tweets containing at least one of the following emoji', query)

csvFile = open('tweets3.csv', 'a')
csvWriter = csv.writer(csvFile)
header = ['id','time', 'tweets','source','entities','retweet','favorite','type']

if lastid == '':
    csvWriter.writerow(header) #write header to csv
    try:
        search = tweepy.Cursor(api.search_tweets,
                          q=query,
                          count=count,
                          result_type='recent',
                          lang='en',
                          until=date).items()
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

else:
    try:
        search = tweepy.Cursor(api.search_tweets,
                               q=query,
                              count=count,
                              result_type='recent',
                              lang='en',
                               until=date,
                              max_id=lastid).items()
        # the bigger the id is, the older the Tweet is.
        # max_id setting means the scraped Tweets is older than the the oldest one we have so far
        for status in search:
            lastid = status.id
            if len(status.text)>1:
                csvWriter.writerow([status.id, status.created_at, status.text,
                                    status.source, status.entities, status.retweet_count,
                                    status.favorite_count, t])#save tweets to csv
    except:
        print('Something wrong!')
        print('The last Tweet:', status.created_at, status.text)
    print('The last id:', lastid)

csvFile.close()

df = pd.read_csv('tweets3.csv',converters={'id':str})
df = df[df['id'] != 'id']
df = df.drop_duplicates()
lastid = df['id'].max()
df.query('type == "disgust"')

# df

####ignore######

# df.to_csv('tweets3.csv')

# df1 = df[df['type'].notnull()]
# # df1 = df1.iloc[:,2:]
# df1

# df2 = df[df['type'].isnull()]
# # df2 = df2.iloc[:,:8]
# # df2.columns = ['id','time','tweets','source','entities','retweet','favorite','type']
# df2